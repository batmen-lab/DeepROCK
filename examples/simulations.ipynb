{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os, torch\n",
    "from numba import cuda \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sys.path.append(\"..\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from src import knockoffs, models, simulations, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Simulation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20000\n",
    "p = 30\n",
    "func_id=1\n",
    "seed=42\n",
    "\n",
    "X = simulations.UniformSampler(p=p, low_list=([0]*p), high_list=([1]*p), seed=seed).sample(n=n)\n",
    "Y, inter_gt, import_gt = simulations.generate_interaction_response(X, func_id)\n",
    "Y = StandardScaler().fit_transform(Y)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Knockoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 00:16:04.716929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46232 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:23:00.0, compute capability: 8.6\n",
      "2023-11-30 00:16:04.731469: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]2023-11-30 00:16:06.172589: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "100%|██████████| 2000/2000 [01:18<00:00, 25.55it/s]\n"
     ]
    }
   ],
   "source": [
    "X_knockoff = knockoffs.KnockoffGAN(X)\n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train DeepROCK model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to train\n",
      "[epoch 1, total 100] train loss: 0.21717, val loss: 0.11095\n",
      "[epoch 2, total 100] train loss: 0.08777, val loss: 0.07268\n",
      "[epoch 3, total 100] train loss: 0.05511, val loss: 0.07430\n",
      "[epoch 4, total 100] train loss: 0.04079, val loss: 0.03098\n",
      "[epoch 5, total 100] train loss: 0.02395, val loss: 0.01910\n",
      "[epoch 6, total 100] train loss: 0.01700, val loss: 0.02667\n",
      "[epoch 7, total 100] train loss: 0.01996, val loss: 0.01479\n",
      "[epoch 8, total 100] train loss: 0.01197, val loss: 0.01733\n",
      "[epoch 9, total 100] train loss: 0.01185, val loss: 0.01118\n",
      "[epoch 10, total 100] train loss: 0.01059, val loss: 0.02523\n",
      "[epoch 11, total 100] train loss: 0.01277, val loss: 0.01019\n",
      "[epoch 12, total 100] train loss: 0.00808, val loss: 0.00798\n",
      "[epoch 13, total 100] train loss: 0.00644, val loss: 0.00677\n",
      "[epoch 14, total 100] train loss: 0.00726, val loss: 0.00714\n",
      "[epoch 15, total 100] train loss: 0.00710, val loss: 0.02520\n",
      "[epoch 16, total 100] train loss: 0.00919, val loss: 0.00573\n",
      "[epoch 17, total 100] train loss: 0.00491, val loss: 0.00465\n",
      "[epoch 18, total 100] train loss: 0.00475, val loss: 0.00437\n",
      "[epoch 19, total 100] train loss: 0.00392, val loss: 0.00481\n",
      "[epoch 20, total 100] train loss: 0.00517, val loss: 0.00466\n",
      "[epoch 21, total 100] train loss: 0.00514, val loss: 0.00572\n",
      "[epoch 22, total 100] train loss: 0.00442, val loss: 0.01045\n",
      "[epoch 23, total 100] train loss: 0.00568, val loss: 0.00496\n",
      "[epoch 24, total 100] train loss: 0.00485, val loss: 0.00440\n",
      "[epoch 25, total 100] train loss: 0.00378, val loss: 0.00410\n",
      "[epoch 26, total 100] train loss: 0.00426, val loss: 0.00533\n",
      "[epoch 27, total 100] train loss: 0.00431, val loss: 0.00461\n",
      "[epoch 28, total 100] train loss: 0.00474, val loss: 0.00580\n",
      "[epoch 29, total 100] train loss: 0.00531, val loss: 0.00477\n",
      "[epoch 30, total 100] train loss: 0.00420, val loss: 0.00703\n",
      "[epoch 31, total 100] train loss: 0.00405, val loss: 0.00485\n",
      "[epoch 32, total 100] train loss: 0.00389, val loss: 0.00479\n",
      "[epoch 33, total 100] train loss: 0.00349, val loss: 0.00327\n",
      "[epoch 34, total 100] train loss: 0.00345, val loss: 0.00316\n",
      "[epoch 35, total 100] train loss: 0.00333, val loss: 0.00406\n",
      "[epoch 36, total 100] train loss: 0.00334, val loss: 0.00439\n",
      "[epoch 37, total 100] train loss: 0.00425, val loss: 0.00651\n",
      "[epoch 38, total 100] train loss: 0.00393, val loss: 0.00382\n",
      "[epoch 39, total 100] train loss: 0.00344, val loss: 0.00469\n",
      "[epoch 40, total 100] train loss: 0.00346, val loss: 0.00366\n",
      "[epoch 41, total 100] train loss: 0.00277, val loss: 0.00416\n",
      "[epoch 42, total 100] train loss: 0.00278, val loss: 0.00284\n",
      "[epoch 43, total 100] train loss: 0.00345, val loss: 0.00468\n",
      "[epoch 44, total 100] train loss: 0.00362, val loss: 0.00290\n",
      "[epoch 45, total 100] train loss: 0.00282, val loss: 0.00249\n",
      "[epoch 46, total 100] train loss: 0.00348, val loss: 0.00288\n",
      "[epoch 47, total 100] train loss: 0.00304, val loss: 0.00274\n",
      "[epoch 48, total 100] train loss: 0.00287, val loss: 0.00544\n",
      "[epoch 49, total 100] train loss: 0.00366, val loss: 0.00380\n",
      "[epoch 50, total 100] train loss: 0.00313, val loss: 0.00300\n",
      "[epoch 51, total 100] train loss: 0.00349, val loss: 0.00301\n",
      "[epoch 52, total 100] train loss: 0.00274, val loss: 0.00371\n",
      "[epoch 53, total 100] train loss: 0.00308, val loss: 0.00533\n",
      "[epoch 54, total 100] train loss: 0.00380, val loss: 0.00661\n",
      "[epoch 55, total 100] train loss: 0.00383, val loss: 0.00336\n",
      "[epoch 56, total 100] train loss: 0.00288, val loss: 0.00381\n",
      "[epoch 57, total 100] train loss: 0.00332, val loss: 0.00264\n",
      "[epoch 58, total 100] train loss: 0.00292, val loss: 0.00304\n",
      "[epoch 59, total 100] train loss: 0.00264, val loss: 0.01404\n",
      "[epoch 60, total 100] train loss: 0.00704, val loss: 0.00717\n",
      "[epoch 61, total 100] train loss: 0.00314, val loss: 0.00273\n",
      "[epoch 62, total 100] train loss: 0.00232, val loss: 0.00295\n",
      "[epoch 63, total 100] train loss: 0.00254, val loss: 0.00294\n",
      "[epoch 64, total 100] train loss: 0.00218, val loss: 0.00249\n",
      "[epoch 65, total 100] train loss: 0.00270, val loss: 0.00377\n",
      "[epoch 66, total 100] train loss: 0.00238, val loss: 0.00239\n",
      "[epoch 67, total 100] train loss: 0.00220, val loss: 0.00216\n",
      "[epoch 68, total 100] train loss: 0.00206, val loss: 0.00240\n",
      "[epoch 69, total 100] train loss: 0.00198, val loss: 0.00207\n",
      "[epoch 70, total 100] train loss: 0.00196, val loss: 0.00235\n",
      "[epoch 71, total 100] train loss: 0.00235, val loss: 0.00327\n",
      "[epoch 72, total 100] train loss: 0.00269, val loss: 0.00242\n",
      "[epoch 73, total 100] train loss: 0.00272, val loss: 0.00323\n",
      "[epoch 74, total 100] train loss: 0.00227, val loss: 0.00467\n",
      "[epoch 75, total 100] train loss: 0.00384, val loss: 0.00470\n",
      "[epoch 76, total 100] train loss: 0.00319, val loss: 0.00223\n",
      "[epoch 77, total 100] train loss: 0.00209, val loss: 0.00330\n",
      "[epoch 78, total 100] train loss: 0.00270, val loss: 0.00203\n",
      "[epoch 79, total 100] train loss: 0.00240, val loss: 0.00342\n",
      "[epoch 80, total 100] train loss: 0.00211, val loss: 0.00203\n",
      "[epoch 81, total 100] train loss: 0.00184, val loss: 0.00415\n",
      "[epoch 82, total 100] train loss: 0.00215, val loss: 0.00238\n",
      "[epoch 83, total 100] train loss: 0.00191, val loss: 0.00142\n",
      "[epoch 84, total 100] train loss: 0.00166, val loss: 0.00392\n",
      "[epoch 85, total 100] train loss: 0.00213, val loss: 0.00228\n",
      "[epoch 86, total 100] train loss: 0.00183, val loss: 0.00183\n",
      "[epoch 87, total 100] train loss: 0.00180, val loss: 0.00174\n",
      "[epoch 88, total 100] train loss: 0.00243, val loss: 0.00196\n",
      "[epoch 89, total 100] train loss: 0.00207, val loss: 0.00440\n",
      "[epoch 90, total 100] train loss: 0.00289, val loss: 0.00316\n",
      "[epoch 91, total 100] train loss: 0.00207, val loss: 0.00156\n",
      "[epoch 92, total 100] train loss: 0.00199, val loss: 0.00324\n",
      "[epoch 93, total 100] train loss: 0.00232, val loss: 0.00355\n",
      "[epoch 94, total 100] train loss: 0.00223, val loss: 0.00274\n",
      "[epoch 95, total 100] train loss: 0.00237, val loss: 0.00513\n",
      "[epoch 96, total 100] train loss: 0.00342, val loss: 0.00200\n",
      "[epoch 97, total 100] train loss: 0.00212, val loss: 0.00357\n",
      "[epoch 98, total 100] train loss: 0.00184, val loss: 0.00159\n",
      "[epoch 99, total 100] train loss: 0.00156, val loss: 0.00465\n",
      "[epoch 100, total 100] train loss: 0.00236, val loss: 0.00183\n"
     ]
    }
   ],
   "source": [
    "nepochs=100\n",
    "weight_decay_const=1e-4\n",
    "batch_size=256\n",
    "learning_rate=0.01\n",
    "\n",
    "X_concat = np.concatenate([X, X_knockoff], axis=1)\n",
    "data_loaders, data_arrs = models.get_torch_loaders(\n",
    "    X=X_concat, Y=Y, batch_size=batch_size, train_ratio=0.5)\n",
    "\n",
    "X_concat_train = data_arrs[\"train\"][0]\n",
    "X_concat_test = data_arrs[\"test\"][0]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = models.DeepROCK(p=p, hidden_dims=[140, 100, 60, 20]).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, amsgrad=True)\n",
    "criterion = torch.nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "model, train_losses, val_losses = models.train(model,\n",
    "    data_loaders=data_loaders, optimizer=optimizer, criterion=criterion, verbose=True,\n",
    "    nepochs=nepochs, decay_const=weight_decay_const, device=device, \n",
    "    early_stopping=False, patience=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:56<00:00,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "global_interaction_import = model.global_feature_interactions(calibrate=True)\n",
    "local_interaction_import = model.local_feature_interactions(X_concat_test, X_concat_train, calibrate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_inter_auc=0.998\tglobal_inter_power=0.545\tglobal_inter_fdp=0.000\n",
      "local_inter_auc=1.000\tlocal_inter_power=0.818\tlocal_inter_fdp=0.000\n"
     ]
    }
   ],
   "source": [
    "target_fdr=0.2\n",
    "\n",
    "global_inter_auc = utils.pairwise_interaction_auc(global_interaction_import, inter_gt)\n",
    "global_sel_inters, global_knockoff_thres = utils.get_selected_interactions(\n",
    "    global_interaction_import, p, target_fdr)\n",
    "global_inter_power = utils.get_interaction_power(global_sel_inters, inter_gt)\n",
    "global_inter_fdp = utils.get_interaction_fdp(global_sel_inters, inter_gt)\n",
    "print(f'global_inter_auc={global_inter_auc:.3f}\\tglobal_inter_power={global_inter_power:.3f}'\n",
    "        f'\\tglobal_inter_fdp={global_inter_fdp:.3f}')\n",
    "\n",
    "local_inter_auc = utils.pairwise_interaction_auc(local_interaction_import, inter_gt)\n",
    "local_sel_inters, local_knockoff_thres = utils.get_selected_interactions(\n",
    "    local_interaction_import, p, target_fdr)\n",
    "local_inter_power = utils.get_interaction_power(local_sel_inters, inter_gt)\n",
    "local_inter_fdp = utils.get_interaction_fdp(local_sel_inters, inter_gt)\n",
    "print(f'local_inter_auc={local_inter_auc:.3f}\\tlocal_inter_power={local_inter_power:.3f}'\n",
    "        f'\\tlocal_inter_fdp={local_inter_fdp:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_feat_inter_df = utils.get_interaction_df(global_interaction_import, p, import_gt, inter_gt)\n",
    "local_feat_inter_df = utils.get_interaction_df(local_interaction_import, p, import_gt, inter_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(x=\"type\", y=\"value\", hue=\"type\", data=global_feat_inter_df, legend=False, ax=axes[0][0])\n",
    "axes[0][0].axhline(y=global_knockoff_thres, color=\"r\", linestyle=\"--\", label=f\"target FDR={args.target_fdr} cutoff\")\n",
    "axes[0][0].set_title(f\"Global Interaction Scores (Act=id Mu=prod demarg=1) Distribution, AUC: {global_inter_auc:.3f}\\n\"\n",
    "    f\"fdp={global_inter_fdp:.3f}, power={global_inter_power:.3f}\")\n",
    "axes[0][0].set_ylabel(\"Interaction Score\")\n",
    "axes[0][0].tick_params(axis='x', labelrotation=30)\n",
    "sns.stripplot(x=\"type\", y=\"value\", hue=\"type\", data=local_feat_inter_df, legend=False, ax=axes[0][1])\n",
    "axes[0][1].axhline(y=local_knockoff_thres, color=\"r\", linestyle=\"--\", label=f\"target FDR={args.target_fdr} cutoff\")\n",
    "axes[0][1].set_title(f\"Local Interaction Scores Distribution, AUC: {local_inter_auc:.3f}\\n\"\n",
    "    f\"fdp={local_inter_fdp:.3f}, power={local_inter_power:.3f}\")\n",
    "axes[0][1].set_ylabel(\"Interaction Score\")\n",
    "axes[0][1].tick_params(axis='x', labelrotation=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "dlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
